{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1 Auto-correct dummy code",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8tOuC1P4vGM"
      },
      "source": [
        "Why is this algorithm important and moreover from the beginning?\n",
        "\n",
        "•\tGarbage in – garbage out principle;\n",
        "\n",
        "•\tEven if auto-correct might be available in the front-end, many do not use it, or it is customized for other type of interactions/domains;\n",
        "\n",
        "•\tIn a conversation, users tend to write very fast and they are making many mistakes;\n",
        "\n",
        "•\tIn reality, humans use this approach and they ask questions only if the targeted, unknown word, is similar with different words, morphologically or/and syntactically;\n",
        "\n",
        "•\tTransferring this issue to CPL would make the conversation too complex.\n",
        "\n",
        "A pre-processing is needed for implementing this algorithm but should not impact the main model. Existing algorithms are suited for this pipeline (spell-check pipelines, masking tasks…)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apr0M6r76YcO"
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUdV_pAX5NuR"
      },
      "source": [
        "Objectives:\n",
        "\n",
        "•\tInserting diacritics (if the case). \n",
        "\n",
        "•\tAddressing abbreviations.\n",
        "\n",
        "•\tCorrecting UNK words with one/two letters deviation. \n",
        "\n",
        "Language specificities: yes (see diacritics)\n",
        "\n",
        "Dependencies: Emoji/Grammar-Semantics\n",
        "\n",
        "Database/ Vocabularies needed: lexicon/ abbreviations/ specific vocabularies/Books& chapters titles\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMLoclREAIq4"
      },
      "source": [
        "# add a corpus of possible inputs for testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcnNuE1AAjw_"
      },
      "source": [
        "# def get_count(word_l):\n",
        "    '''\n",
        "    Input:\n",
        "        word_l: a set of words representing the corpus. \n",
        "    Output:\n",
        "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
        "    '''\n",
        "    word_count_dict = {}  # fill this with word counts\n",
        "    word_count_dict = Counter(word_l)  \n",
        "    return word_count_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbWbimDS4t7T"
      },
      "source": [
        "# IN: the user input (list with words and characters)\n",
        "# OUT: corrected input (list with words and characters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcTHymFx8EPZ"
      },
      "source": [
        "#Code: transform input in a list of words and characters (words devided by space, no not miss any characters from the input for future pipelines, no sub-letters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEOdMfdL_Ba_"
      },
      "source": [
        "# def process_data(file_name):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "        A file_name which is found in your current directory. You just have to read it in. \n",
        "    Output: \n",
        "        words: a list containing all the words in the corpus (text file you read). \n",
        "    \"\"\"\n",
        "    words = [] # return this variable correctly\n",
        "\n",
        "    with open(file_name) as f:\n",
        "        file_name_data = f.read()\n",
        "    words = re.findall('\\w+',file_name_data)\n",
        "    \n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHtiVtsJ9wVJ"
      },
      "source": [
        "To dos:\n",
        "1.\tA local input processing was needed. Only words are in scope of this algorithm.\n",
        "2.\tSearching for UNK words in the input corpus.\n",
        "3.\tSee overlaps between specific vocabularies and general vocabularies.\n",
        "4.\tDeploying algorithm for mapping UNK with vocabularies (one & two letter deviations will be addressed) – in that way, if the specific vocabulary words have articles, they will be brought to their base.\n",
        "5.\tIf in the mapping process more than one different vocabulary word will be found, all words will be marked for Grammar/Semantics analysis.\n",
        "6.\tAbbreviations will be mapped with Abbreviation's vocabularies and if found will be marked for Emoji algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhn1mhEb9X-o"
      },
      "source": [
        "# your code HERE! - Use existing codes. Special focus on diacritics and special language characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqpxVTNa-NnO"
      },
      "source": [
        "# example of CODE! Do not use w/o adaptation!!!!!!!!!! (see to dos and objectives)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSRXvDzv_zwn"
      },
      "source": [
        "# def get_probs(word_count_dict):\n",
        "    '''\n",
        "    Input:\n",
        "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
        "    Output:\n",
        "        probs: A dictionary where keys are the words and the values are the probability that a word will occur. \n",
        "    '''\n",
        "    probs = {}  # return this variable correctly\n",
        "    \n",
        "    m = sum(word_count_dict.values())\n",
        "    for key in word_count_dict.keys():\n",
        "        probs[key] = word_count_dict[key] / m\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_niKwbIfBHcu"
      },
      "source": [
        "# def delete_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the string/word for which you will generate all possible words \n",
        "                in the vocabulary which have 1 missing character\n",
        "    Output:\n",
        "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
        "    '''\n",
        "    \n",
        "    delete_l = []\n",
        "    split_l = []\n",
        "    \n",
        "    for c in range(len(word)):\n",
        "        split_l.append((word[:c],word[c:]))\n",
        "    for a,b in split_l:\n",
        "        delete_l.append(a+b[1:])\n",
        "\n",
        "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
        "\n",
        "    return delete_l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTxGqx60Bbvn"
      },
      "source": [
        "# def switch_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: input string\n",
        "     Output:\n",
        "        switches: a list of all possible strings with one adjacent charater switched\n",
        "    ''' \n",
        "    \n",
        "    switch_l = []\n",
        "    split_l = []\n",
        "    \n",
        "    len_word=len(word)\n",
        "    for c in range(len_word):\n",
        "        split_l.append((word[:c],word[c:]))\n",
        "    switch_l = [a + b[1] + b[0] + b[2:] for a,b in split_l if len(b) >= 2]\n",
        "    \n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
        "\n",
        "    return switch_l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkwcpNMaBm8P"
      },
      "source": [
        "# def replace_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word \n",
        "    Output:\n",
        "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
        "    ''' \n",
        "    \n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    replace_l = []\n",
        "    split_l = []\n",
        "    \n",
        "    for c in range(len(word)):\n",
        "        split_l.append((word[0:c],word[c:]))\n",
        "    replace_l = [a + l + (b[1:] if len(b)> 1 else '') for a,b in split_l if b for l in letters]\n",
        "    replace_set=set(replace_l)    \n",
        "    replace_set.remove(word)\n",
        "    \n",
        "    # turn the set back into a list and sort it, for easier viewing\n",
        "    replace_l = sorted(list(replace_set))\n",
        "    \n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
        "    \n",
        "    return replace_l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYuTjW_KCHtn"
      },
      "source": [
        "# def insert_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word \n",
        "    Output:\n",
        "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
        "    ''' \n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    insert_l = []\n",
        "    split_l = []\n",
        "    \n",
        "    for c in range(len(word)+1):\n",
        "        split_l.append((word[0:c],word[c:]))\n",
        "    insert_l = [ a + l + b for a,b in split_l for l in letters]\n",
        "\n",
        "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
        "    \n",
        "    return insert_l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW01sUx3CMkW"
      },
      "source": [
        "# def edit_one_letter(word, allow_switches = True):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
        "    Output:\n",
        "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
        "    \"\"\"\n",
        "    \n",
        "    edit_one_set = set()\n",
        "    \n",
        "    edit_one_set.update(delete_letter(word))\n",
        "    if allow_switches:\n",
        "        edit_one_set.update(switch_letter(word))\n",
        "    edit_one_set.update(replace_letter(word))\n",
        "    edit_one_set.update(insert_letter(word))\n",
        "\n",
        "    return edit_one_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNI5fVTpCfR_"
      },
      "source": [
        "# def edit_two_letters(word, allow_switches = True):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word \n",
        "    Output:\n",
        "        edit_two_set: a set of strings with all possible two edits\n",
        "    '''\n",
        "    \n",
        "    edit_two_set = set()\n",
        "    \n",
        "    edit_one = edit_one_letter(word,allow_switches=allow_switches)\n",
        "    for w in edit_one:\n",
        "        if w:\n",
        "            edit_two = edit_one_letter(w,allow_switches=allow_switches)\n",
        "            edit_two_set.update(edit_two)\n",
        "  \n",
        "    \n",
        "    return edit_two_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaBjj_W6CmQ5"
      },
      "source": [
        "# def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
        "    '''\n",
        "    Input: \n",
        "        word: a user entered string to check for suggestions\n",
        "        probs: a dictionary that maps each word to its probability in the corpus\n",
        "        vocab: a set containing all the vocabulary\n",
        "        n: number of possible word corrections you want returned in the dictionary\n",
        "    Output: \n",
        "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
        "    '''\n",
        "    \n",
        "    suggestions = []\n",
        "    n_best = []\n",
        "   \n",
        "    suggestions = list((word in vocab and word) or edit_one_letter(word).intersection(vocab) or edit_two_letters(word).intersection(vocab))\n",
        "    n_best = [[s,probs[s]] for s in list(reversed(suggestions))]\n",
        "    \n",
        "    if verbose: print(\"suggestions = \", suggestions)\n",
        "\n",
        "    return n_best"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uoM5icUDVXg"
      },
      "source": [
        "# def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
        "    '''\n",
        "    Input: \n",
        "        source: a string corresponding to the string you are starting with\n",
        "        target: a string corresponding to the string you want to end with\n",
        "        ins_cost: an integer setting the insert cost\n",
        "        del_cost: an integer setting the delete cost\n",
        "        rep_cost: an integer setting the replace cost\n",
        "    Output:\n",
        "        D: a matrix of len(source)+1 by len(target)+1 containing minimum edit distances\n",
        "        med: the minimum edit distance (med) required to convert the source string to the target\n",
        "    '''\n",
        "    # use deletion and insert cost as  1\n",
        "    m = len(source) \n",
        "    n = len(target) \n",
        "    #initialize cost matrix with zeros and dimensions (m+1,n+1) \n",
        "    D = np.zeros((m+1, n+1), dtype=int) \n",
        "    \n",
        "    \n",
        "    # Fill in column 0, from row 1 to row m, both inclusive\n",
        "    for row in range(1,m+1): # Replace None with the proper range\n",
        "        D[row,0] = D[row-1,0] + del_cost\n",
        "        \n",
        "    # Fill in row 0, for all columns from 1 to n, both inclusive\n",
        "    for col in range(1,n+1): # Replace None with the proper range\n",
        "        D[0,col] = D[0,col-1] + ins_cost\n",
        "        \n",
        "    # Loop through row 1 to row m, both inclusive\n",
        "    for row in range(1,m+1): \n",
        "        \n",
        "        # Loop through column 1 to column n, both inclusive\n",
        "        for col in range(1,n+1):\n",
        "            \n",
        "            # Intialize r_cost to the 'replace' cost that is passed into this function\n",
        "            r_cost = rep_cost\n",
        "            \n",
        "            # Check to see if source character at the previous row\n",
        "            # matches the target character at the previous column, \n",
        "            if source[row-1] == target[col-1]:\n",
        "                # Update the replacement cost to 0 if source and target are the same\n",
        "                r_cost = 0\n",
        "                \n",
        "            # Update the cost at row, col based on previous entries in the cost matrix\n",
        "            # Refer to the equation calculate for D[i,j] (the minimum of three calculated costs)\n",
        "            D[row,col] = min([D[row-1,col]+del_cost, D[row,col-1]+ins_cost, D[row-1,col-1]+r_cost])\n",
        "          \n",
        "    # Set the minimum edit distance with the cost found at row m, column n\n",
        "    med = D[m,n]\n",
        "    \n",
        "    return D, med"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}