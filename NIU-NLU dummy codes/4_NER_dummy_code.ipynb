{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. NER - dummy code",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOpCTgt0arRj"
      },
      "source": [
        "We need to identify the commercial/core domain in every input, to see if we are dealing with core-input. For that reason, we will search for NERs and classify them in NER1, NER2, NER3…. For example, in a case study of restaurants recommendation digitalization, NER1=name of the restaurants, NER2=locations, NER3=types of cuisine, NER4=types of food, NER5=names of chefs, NER6= word in the gastronomic dictionary, NER7= other generalities… For multi-domains/industries, the customization process will include providing the databases split by NER and importance of NERs. \n",
        "\n",
        "This pipeline is very important to determine the Subject and Complements of the core-input. Once the domain is determined, it will remain for the next inputs of the user, if no other NER domains are inputted. \n",
        "\n",
        "NER can include some generalities (general inputs of the user - GER) that can be common with other domains and can create confusion as it might have different meanings in different domains. The model implies a prioritization and if the user is unsatisfied, either he will give additional information, or the bot will search for back-up answers. Most probably the user will understand that it is a multi-domain bot, and it is important to give a complete input which will be captured by the sentence-intent that has also the benefits of the multi-domain conversational bot implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B93NB4s6ahyP"
      },
      "source": [
        "# IN: input from Composed words + list with processed+corrected words\n",
        "# OUT: send NER to subsequent pipelines: SPCA/embeddings/ triggering words/CVM;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzr54n27a6j0"
      },
      "source": [
        "Objectives:\n",
        "\n",
        "•\tDetermining if the input is a core input or not. Make NER classification and GDPR clean-ups.\n",
        "\n",
        "Language specificities: no;\n",
        "\n",
        "Dependencies: SPCA/embeddings/ triggering words/CVM;\n",
        "\n",
        "Database/ Vocabularies needed: NER & GER vocabularies /Books- NER vocabularies.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdd5ccndbCbZ"
      },
      "source": [
        "# To dos:\n",
        "# 1.\tIdentify NER/GER by importance and classify them accordingly: NER1, NER2, NER3…. The same with books NER: NER01/NER02…. Additional NERs will be mapped through integration with existing slots available.\n",
        "# 2.\tIf we have other upper-case words inside the sentences that don’t appear in the database, it will be eliminated for GDPR reasons. \n",
        "# 3.\tIdentifications of the domains/industry based on the NER identifications. If NER from more domains/industries are identified, then the first counts for the domain identification.\n",
        "# 4.\tIf NER 1/NER1.0 is identified, then it will be marked as Subject. If we have NERs from the same domains then the prioritization counts and the 2nd,…NER will be marked as complements. If deep conversational intents do not have NERs, and the subject is CVM, 3rd row.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xUcC4gObLQB"
      },
      "source": [
        "Adapted code (existing code that can be adapted to cover the pipeline specificities)"
      ]
    }
  ]
}