{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12. Reply dummy code",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKGEthyo4xty"
      },
      "source": [
        "Replies/Reply is referring to the action of the user resulting from other actions of the bot (answers, questions, other). The bot expects these replies to be in short utterances and will evaluate for sentiment analysis all the sentences from the input (after they went through splitting sentences) but will take into consideration also the cases when the replies are pretty complex (in scope of SPCA pipelines). In this pipeline we analyze only the short utterance replies and consequently we can make exceptions from the fundamentals and also use data augmentation through translation if there aren’t any available datasets or pre-trained models for sentiment analysis tasks. We will also choose to have our own created datasets for fine tuning as we have experience in screenplays and an intent based solution (aka. Rasa) is suited for this pipeline as we need to know what kind of reply the user is giving and we can track the different intents.\n",
        "\n",
        "We will go deeper in evaluating the negative/positive sentiment and split these sentiments in three:\n",
        "\n",
        "•\tConfirmation and negation;\n",
        "\n",
        "•\tSatisfied & unsatisfied;\n",
        "\n",
        "•\tUnderstanding & misunderstanding.\n",
        "\n",
        "Please note that the bot is not responding to the utterances identified as the user’s replies but is only sending the sentiment analysis evaluation for the CPL layer. They need to be evaluated in context in order to understand why the user is having a positive sentiment or a negative one. Using an existing model for the sentiment analysis task, pre-trained on social media datasets and fine-tuned on BST (w/t the generative model part) can be a solution. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJDekt-F4sEq"
      },
      "source": [
        "# IN: every sentences from splitting sentences\n",
        "# OUT: classigications sent to reaction analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHiCuLjN_DMY"
      },
      "source": [
        "Objectives:\n",
        "\n",
        "•\tEvaluating the replies of the users’ utterance in a short sentence;\n",
        "\n",
        "•\tThe replies can be in a standalone input, or together with other types of inputs (core-inputs/deep conversational…);\n",
        "\n",
        "Language specificities: no;\n",
        "\n",
        "Dependencies: Splitting sentences/ Reaction analysis;\n",
        "\n",
        "Database/ Vocabularies needed: 3 databases with 3 types of replies: confirmations / satisfactions/ understanding, divided equally between positive and negative and with 80-20 training vs testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HcGloep_Qc3"
      },
      "source": [
        "#To dos:\n",
        "# 1.\tApply an intent based algorithm on every short sentence to see if the user is giving the bot any replies (3 types).\n",
        "# 2.\tClassify the replies in 6 categories (understanding, misunderstanding, confirmation, negation, satisfied, unsatisfied) and send them to the Reaction analysis pipeline.\n",
        "# 3.\tEliminating the sentence from Pirkin Model if a valid reply is identified. This sentence (in the case the input has more sentences) will be evaluated for chitchat purposes also.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kguz-ZS9_lTt"
      },
      "source": [
        "Use existing codes – \n",
        "\n",
        "As we are evaluating only short possible sentences, any existing code that can track down the six categories can be used.\n",
        "\n",
        "possible solutions:\n",
        "\n",
        "1. data augmentation through translation can be a solution if no datasets available\n",
        "\n",
        "2. sentiment analysis tasks (using any model: classification, probabilistic, sequential, attention)\n",
        "\n",
        "3. intent based algorithms by labeling the possible replies - recommended"
      ]
    }
  ]
}