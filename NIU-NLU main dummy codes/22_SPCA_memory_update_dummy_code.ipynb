{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "22. SPCA memory update dummy code",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iorSmXAPTs1W"
      },
      "source": [
        "One of the main reasons for choosing this model is the possibility to keep past interactions in a structural way and update the sentence-intent/SPCA/input with every turn, covering the multi-session-conversations. Usually, a user will not repeat himself and many times the subject/predicate or even complement/attribute remains unchanged thought-out multiple turns or until a final answer is provided by the bot in the consultancy session. A reset pipeline in CPL will decide what information needs to be kept, depending on AVM/IVM, and it will trigger an algorithm in the present pipeline, SPCA-memory update, that’s choosing how the final SPCA will look like, by considering the present SPCA and the past one. Implicating the reset pipeline in the memory update will be beneficial, in order not to create redundancies or use already dismissed past utterances that a summarization or a retrieval will not be able to take into consideration.\n",
        "\n",
        "In order to implement a long-term-memory update on a back-up model that is using an E2E model we will add to this pipeline a summarization-augmentation (XU et al.,2021)\n",
        "\n",
        "Chronologically, this pipeline must be after CPL and NOG, but because it is an important pipeline for the NIU we will present it here. Please note that at this point, the pipeline augmentation-through-conversation has already made some steps towards the long-term memory update.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcQJDVouUCic"
      },
      "source": [
        "#IN: past history inputs\n",
        "#OUT: updated SPCA with the past utterances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBd3ydcIUFDt"
      },
      "source": [
        "Objectives:\n",
        "\n",
        "•\tMaking an update between present SPCA and past one that went through Reset pipeline from CPL layer;\n",
        "\n",
        "•\tMaking rules between present SPCA that can be SPCA1/SPCA3/SPCA4 and past ones with the same possibilities. SPCA2 is not in scope of memory update (it's treated in CPL);\n",
        "\n",
        "•\tImplementing a summarization-augmentation algorithm for the E2E model – back-up model\n",
        "\n",
        "Dependencies: NOG/Reset/Domain validation/ IVM/AVM/ CVM;\n",
        "\n",
        "Database/ Vocabularies needed:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSjHQMEuUPe0"
      },
      "source": [
        "# To dos:\n",
        "# Step 1. Assess if we have past SPCA and its type- Verify Reset pipeline & IVM & AVM. If not, SPCA final = SPCA & stop other steps. \n",
        "# Step 2. Verify if the present SPCA has the same type as the past SPCA. If not, skip Step 3.\n",
        "# Step 3. Prioritize the present SPCA. The Complement and Attribute can only be updated together (Or NER and Attribute). In case of no predicate in the current SPCA, the CVM final=CVM past (-1). In case of no subject in present SPCA, the final S = past S. The same with the Complement and the Attribute. Exceptions for specific additional questions. After update, the Domain validation pipeline will be repeated.\n",
        "# Step 4. If the present SPCA and past SPCA are of different types, no update will be made and final SPCA= present SPCA.\n",
        "# Step 5. If the present SPCA is SPCA0 and we have past SPCAs, the same rules from Step3 apply.\n",
        "# Step 6. If back-up model is active, we will implement a summarization-augmentation algorithm for long-term memory update (XU et al.,2021).\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XbWNu4iUsCF"
      },
      "source": [
        "build code from scratch + code from (XU et al.,2021)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}